{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 811457 entries, 0 to 811456\n",
      "Data columns (total 6 columns):\n",
      "waferMap          811457 non-null object\n",
      "dieSize           811457 non-null float64\n",
      "lotName           811457 non-null object\n",
      "waferIndex        811457 non-null float64\n",
      "trianTestLabel    811457 non-null object\n",
      "failureType       811457 non-null object\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 37.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_pickle(os.path.join(os.getcwd(), 'input\\LSWMD.pkl'))\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 811457 entries, 0 to 811456\n",
      "Data columns (total 6 columns):\n",
      "waferMap          811457 non-null object\n",
      "dieSize           811457 non-null float64\n",
      "lotName           811457 non-null object\n",
      "waferIndex        811457 non-null float64\n",
      "trianTestLabel    811457 non-null object\n",
      "failureType       811457 non-null object\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 37.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waferMap</th>\n",
       "      <th>dieSize</th>\n",
       "      <th>lotName</th>\n",
       "      <th>waferIndex</th>\n",
       "      <th>trianTestLabel</th>\n",
       "      <th>failureType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[Training]]</td>\n",
       "      <td>[[none]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[[Training]]</td>\n",
       "      <td>[[none]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[Training]]</td>\n",
       "      <td>[[none]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[[Training]]</td>\n",
       "      <td>[[none]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[Training]]</td>\n",
       "      <td>[[none]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            waferMap  dieSize lotName  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0    lot1   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0    lot1   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0    lot1   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0    lot1   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0    lot1   \n",
       "\n",
       "   waferIndex trianTestLabel failureType  \n",
       "0         1.0   [[Training]]    [[none]]  \n",
       "1         2.0   [[Training]]    [[none]]  \n",
       "2         3.0   [[Training]]    [[none]]  \n",
       "3         4.0   [[Training]]    [[none]]  \n",
       "4         5.0   [[Training]]    [[none]]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waferMap</th>\n",
       "      <th>dieSize</th>\n",
       "      <th>lotName</th>\n",
       "      <th>waferIndex</th>\n",
       "      <th>trianTestLabel</th>\n",
       "      <th>failureType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>811452</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>lot47542</td>\n",
       "      <td>23.0</td>\n",
       "      <td>[[Test]]</td>\n",
       "      <td>[[Edge-Ring]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811453</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1,...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>lot47542</td>\n",
       "      <td>24.0</td>\n",
       "      <td>[[Test]]</td>\n",
       "      <td>[[Edge-Loc]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811454</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>lot47542</td>\n",
       "      <td>25.0</td>\n",
       "      <td>[[Test]]</td>\n",
       "      <td>[[Edge-Ring]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811455</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>lot47543</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811456</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>lot47543</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 waferMap  dieSize   lotName  \\\n",
       "811452  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...    600.0  lot47542   \n",
       "811453  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1,...    600.0  lot47542   \n",
       "811454  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...    600.0  lot47542   \n",
       "811455  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,...    600.0  lot47543   \n",
       "811456  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...    600.0  lot47543   \n",
       "\n",
       "        waferIndex trianTestLabel    failureType  \n",
       "811452        23.0       [[Test]]  [[Edge-Ring]]  \n",
       "811453        24.0       [[Test]]   [[Edge-Loc]]  \n",
       "811454        25.0       [[Test]]  [[Edge-Ring]]  \n",
       "811455         1.0             []             []  \n",
       "811456         2.0             []             []  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим разметку паттернов и их количество для каждой вафли "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\neuralnets\\lib\\site-packages\\pandas\\core\\internals.py:5152: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = op(a, b)\n",
      "C:\\Users\\user\\Anaconda3\\envs\\neuralnets\\lib\\site-packages\\pandas\\core\\missing.py:51: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask = arr == x\n"
     ]
    }
   ],
   "source": [
    "df_all['failureNum'] = df_all.failureType\n",
    "df_all['trainTestNum'] = df_all.trianTestLabel\n",
    "\n",
    "mapping_type={'Center':0,'Donut':1,'Edge-Loc':2,\n",
    "              'Edge-Ring':3,'Loc':4,'Random':5,\n",
    "              'Scratch':6,'Near-full':7,'none':8}\n",
    "\n",
    "mapping_traintest = {'Training':0, 'Test':1}\n",
    "\n",
    "df_all = df_all.replace({'failureNum':mapping_type, 'trainTestNum':mapping_traintest})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделим датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withlabel = df_all[(df_all['failureNum'] >= 0) & df_all['failureNum'] <=8]\n",
    "df_withlabel = df_withlabel.reset_index()\n",
    "\n",
    "df_withpattern = df_all[(df_all['failureNum'] >= 0) & (df_all['failureNum'] <= 7)]\n",
    "df_withpattern = df_withpattern.reset_index()\n",
    "\n",
    "df_nopattern = df_all[(df_all['failureNum'] == 8)]\n",
    "\n",
    "df_withlabel.shape, df_withpattern.shape, df_nopattern.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим на статистику данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(24, 7)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1.5]) \n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "\n",
    "no_wafers=[df_all.shape[0] - df_withlabel.shape[0], \n",
    "           df_withpattern.shape[0], df_nopattern.shape[0]]\n",
    "\n",
    "colors = ['royalblue', 'lightblue', 'steelblue']\n",
    "explode = (0.1, 0, 0)\n",
    "labels = ['no-label','label&pattern','label&non-pattern']\n",
    "ax1.pie(no_wafers, explode=explode, \n",
    "        labels=labels, colors=colors, \n",
    "        autopct='%1.1f%%', shadow=True, startangle=140,\n",
    "       textprops={'fontsize': 15})\n",
    "\n",
    "uni_pattern=np.unique(df_withpattern.failureNum, return_counts=True)\n",
    "labels2 = ['','Center','Donut',\n",
    "           'Edge-Loc','Edge-Ring','Loc',\n",
    "           'Random','Scratch','Near-full']\n",
    "\n",
    "ax2.bar(uni_pattern[0], uni_pattern[1] / df_withpattern.shape[0],\n",
    "            color='steelblue', align='center', alpha=0.9)\n",
    "ax2.set_title(\"failure type frequency\", fontsize=15)\n",
    "ax2.set_ylabel(\"% of pattern wafers\", fontsize=15)\n",
    "ax2.set_xticklabels(labels2, fontsize=15)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нарисуем вафли "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 10, ncols = 10, figsize=(20, 20))\n",
    "ax = ax.ravel(order='C')\n",
    "for i in range(100):\n",
    "    img = df_withpattern.waferMap[i]\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(df_withpattern.failureType[i][0][0], fontsize=20)\n",
    "    ax[i].set_xlabel(df_withpattern.index[i], fontsize=20)\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0,1,2,3,4,5,6,7]\n",
    "labels2 = ['Center','Donut','Edge-Loc','Edge-Ring','Loc','Random','Scratch','Near-full']\n",
    "\n",
    "for k in x:\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 10, figsize=(18, 12))\n",
    "    ax = ax.ravel(order='C')\n",
    "    for j in [k]:\n",
    "        img = df_withpattern.waferMap[df_withpattern.failureType==labels2[j]]\n",
    "        for i in range(10):\n",
    "            ax[i].imshow(img[img.index[i]])\n",
    "            ax[i].set_title(df_withpattern.failureType[img.index[i]][0][0], fontsize=20)\n",
    "            ax[i].set_xlabel(df_withpattern.index[img.index[i]], fontsize=20)\n",
    "            ax[i].set_xticks([])\n",
    "            ax[i].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [9,340, 3, 16, 0, 25, 84, 37]\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 2, ncols = 4, figsize=(20, 10))\n",
    "ax = ax.ravel(order='C')\n",
    "for i in range(8):\n",
    "    img = df_withpattern.waferMap[x[i]]\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(df_withpattern.failureType[x[i]][0][0],fontsize=24)\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withpattern.waferMap[1].shape\n",
    "df_withpattern.failureNum[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "import gc \n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "IMAGE_DIMS = (52 , 52 , 1)\n",
    "BATCH_SIZE = 720"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape всех карт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузить синтетическую базу и смешать с реальными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_pickle('output/syntesis_df')\n",
    "df['failureType'] = df['failureType'].map(lambda label: [[label]])\n",
    "\n",
    "df_withpattern['waferMap'] =df_withpattern['waferMap'].map(lambda waf_map: \n",
    "                                    cv2.resize(waf_map, \n",
    "                                               dsize=(IMAGE_DIMS[0], IMAGE_DIMS[1]), \n",
    "                                               interpolation=cv2.INTER_NEAREST)) \n",
    "\n",
    "real_center = df_withpattern[df_withpattern['failureType'] == 'Center'].iloc[:100]\n",
    "real_ring = df_withpattern[df_withpattern['failureType'] == 'Donut'].iloc[:50]\n",
    "real_edge_loc = df_withpattern[df_withpattern['failureType'] == 'Edge-Loc'].iloc[:500]\n",
    "real_edge_ring = df_withpattern[df_withpattern['failureType'] == 'Edge-Ring'].iloc[:500]\n",
    "real_loc = df_withpattern[df_withpattern['failureType'] == 'Loc'].iloc[:350]\n",
    "real_random = df_withpattern[df_withpattern['failureType'] == 'Random'].iloc[:80]\n",
    "real_scratch = df_withpattern[df_withpattern['failureType'] == 'Scratch'].iloc[:100]\n",
    "real_near_full = df_withpattern[df_withpattern['failureType'] == 'Near-full'].iloc[:10]\n",
    "\n",
    "df = pd.concat([df, real_center, real_ring, real_edge_loc,\n",
    "               real_edge_ring, real_loc, real_random, \n",
    "               real_scratch, real_near_full], sort=False)\n",
    "gc.collect()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_center = df_withpattern[df_withpattern['failureType'] == 'Center'].iloc[100:]\n",
    "real_ring = df_withpattern[df_withpattern['failureType'] == 'Donut'].iloc[50:]\n",
    "real_edge_loc = df_withpattern[df_withpattern['failureType'] == 'Edge-Loc'].iloc[700:]\n",
    "real_edge_ring = df_withpattern[df_withpattern['failureType'] == 'Edge-Ring'].iloc[500:]\n",
    "real_loc = df_withpattern[df_withpattern['failureType'] == 'Loc'].iloc[400:]\n",
    "real_random = df_withpattern[df_withpattern['failureType'] == 'Random'].iloc[80:]\n",
    "real_scratch = df_withpattern[df_withpattern['failureType'] == 'Scratch'].iloc[150:]\n",
    "real_near_full = df_withpattern[df_withpattern['failureType'] == 'Near-full'].iloc[10:]\n",
    "\n",
    "real_test = pd.concat([real_center, real_ring, real_edge_loc,\n",
    "                       real_edge_ring, real_loc, real_random, \n",
    "                       real_scratch, real_near_full], sort=False)\n",
    "\n",
    "real_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генератор изображений категорий "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen_cat(in_df, batch_size=BATCH_SIZE):\n",
    "    all_batches = in_df.sample(frac=1)\n",
    "    out_map = []\n",
    "    out_class = []\n",
    "    while True:\n",
    "        for index, row in in_df.iterrows():\n",
    "            out_map += [np.expand_dims(row.waferMap, -1)]\n",
    "            out_class += [row.failureNum]\n",
    "            if len(out_map) >= batch_size:\n",
    "                out_map = np.array(out_map)\n",
    "                out_map = out_map.reshape(out_map.shape[0], IMAGE_DIMS[0], IMAGE_DIMS[1], 1)\n",
    "                yield np.stack(out_map, 0), np.array(np_utils.to_categorical(out_class, num_classes=8))\n",
    "                out_map = []\n",
    "                out_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генератор изображений MultiLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "labels = [None] * df.shape[0]\n",
    "\n",
    "i = 0\n",
    "for index, row in df.iterrows():\n",
    "    label = row.failureType[0]\n",
    "    labels[i] = label\n",
    "    i += 1\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(labels)\n",
    "print(labels.shape)\n",
    "\n",
    "print(\"class labels:\")\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "    print(\"{}. {}\".format(i + 1, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen_mul(in_df, batch_size=BATCH_SIZE):\n",
    "    all_batches = in_df.sample(frac=1)\n",
    "    out_map = []\n",
    "    out_class = []\n",
    "    while True:\n",
    "        for index, row in in_df.iterrows():\n",
    "            out_map += [np.expand_dims(row.waferMap, -1)]\n",
    "            out_class += [row.failureType[0]]\n",
    "            if len(out_map) >= batch_size:\n",
    "                out_map = np.array(out_map)\n",
    "                out_map = out_map.reshape(out_map.shape[0], IMAGE_DIMS[0], IMAGE_DIMS[1], 1)\n",
    "                yield np.stack(out_map, 0), mlb.transform(out_class)\n",
    "                out_map = []\n",
    "                out_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделим датасет на train/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2)\n",
    "train_df.shape[0], valid_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделим датасет на train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "train.shape[0], validate.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "valid_x, valid_y = next(make_image_gen_mul(validate))\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аугментация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 15,  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True)\n",
    "\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "label_gen = ImageDataGenerator()\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        # keep the seeds syncronized otherwise the augmentation \n",
    "        # to the images is different from the masks\n",
    "        g_x = image_gen.flow(in_x, \n",
    "                             batch_size = in_x.shape[0])\n",
    "\n",
    "        yield next(g_x), in_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = make_image_gen_mul(train)\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape)\n",
    "print('y', train_y.shape)\n",
    "cur_gen = create_aug_gen(train_gen)\n",
    "t_x, t_y = next(cur_gen)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 16\n",
    "plt.imshow(valid_x[n,:,:,0])\n",
    "print(valid_y[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим модель "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallerVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, finalAct=\"softmax\"):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        # and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "\n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", \n",
    "                         input_shape=(IMAGE_DIMS[0], IMAGE_DIMS[1], 1)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # use a *softmax* activation for single-label classification\n",
    "        # and *sigmoid* activation for multi-label classification\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(finalAct))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "                            depth=IMAGE_DIMS[2], classes=8, \n",
    "                            finalAct=\"sigmoid\")\n",
    " \n",
    "# initialize the optimizer\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, dice_coef, acc, _ = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\n - Testing loss: {:.4f} - dice_coef: {:.4f} - acc: {:.4f}\\n'.format(loss, dice_coef, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "weight_path=\"C:\\\\Users\\\\user\\\\Python_Code\\\\Data Monsters\\\\output\\\\models\\\\VGG16_easy_weights.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_acc', factor=0.33,\n",
    "                                   patience=3, verbose=1, mode='max',\n",
    "                                   min_delta=0.0001, cooldown=0, min_lr=1e-6)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", verbose=2, \n",
    "                      patience=7)\n",
    "\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint, reduceLROnPlat]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3, decay=1e-6), \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", \n",
    "                      metrics.categorical_accuracy])\n",
    "\n",
    "def reset_weights(model):\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)\n",
    "            \n",
    "reset_weights(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_train_cat = make_image_gen_cat(train)\n",
    "gen_valid_cat = make_image_gen_cat(validate)\n",
    "\n",
    "aug_gen_cat = create_aug_gen(make_image_gen_mul(train))\n",
    "\n",
    "\n",
    "net = model.fit_generator(gen_train_cat,\n",
    "                          steps_per_epoch = 100,\n",
    "                          epochs = EPOCHS,\n",
    "                          validation_data = gen_valid_cat,\n",
    "                          validation_steps = 320,\n",
    "                          callbacks = callbacks_list,\n",
    "                          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), net.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), net.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "# plot the trainingaccuracy\n",
    "plt.plot(np.arange(0, N), net.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), net.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:20]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "net = model.fit_generator(gen_train_cat,\n",
    "                          steps_per_epoch = 100,\n",
    "                          epochs = EPOCHS//2,\n",
    "                          validation_data = gen_valid_cat,\n",
    "                          validation_steps = 320,\n",
    "                          callbacks = callbacks_list,\n",
    "                          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "gen_train_mul = make_image_gen_mul(train)\n",
    "gen_valid_mul = make_image_gen_mul(validate)\n",
    "\n",
    "aug_gen_mul = create_aug_gen(make_image_gen_mul(train))\n",
    "\n",
    "net = model.fit_generator(gen_train_mul,\n",
    "                          steps_per_epoch = 100,\n",
    "                          epochs = EPOCHS,\n",
    "                          validation_data = gen_valid_mul,\n",
    "                          validation_steps = 320,\n",
    "                          callbacks = callbacks_list,\n",
    "                          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the training loss\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), net.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), net.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "# plot the trainingaccuracy\n",
    "plt.plot(np.arange(0, N), net.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), net.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним веса модели\n",
    "model.save_weights(weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравниваем с предикты с ответами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_map = []\n",
    "out_class = []\n",
    "for index, row in real_test.iterrows():\n",
    "    out_map += [np.expand_dims(row.waferMap, -1)]\n",
    "    out_class += [row.failureNum]\n",
    "\n",
    "out_map = np.array(out_map)\n",
    "out_map = out_map.reshape(out_map.shape[0], 92, 92, 1)\n",
    "out_map = np.stack(out_map, 0)\n",
    "out_class = np.array(np_utils.to_categorical(out_class, num_classes=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_test_pred = model.predict(out_map)\n",
    "y_test = out_class\n",
    "\n",
    "print(y_test_pred.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 78\n",
    "print((y_test[n]))\n",
    "\n",
    "for (label, p) in zip(mlb.classes_, y_test_pred[n]):\n",
    "    print(\"{}: {:.2f}%\".format(label, p * 100))\n",
    "    \n",
    "    \n",
    "plt.imshow(out_map[n][:,:,0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_test_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=(15, 8)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1]) \n",
    "\n",
    "## Plot non-normalized confusion matrix\n",
    "plt.subplot(gs[0])\n",
    "plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(gs[1])\n",
    "plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.savefig('output/mix_syntesis_6.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Center':0,'Ring':1,'Edge-Loc':2,\n",
    "\n",
    "'Edge-Ring':3,'Loc':4,'Random':5,\n",
    "\n",
    "'Scrath':6, 'Near-Full':7, 'Curved-Scrath':8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
